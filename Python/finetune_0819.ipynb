{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 实验说明\n",
    "\n",
    "在深度学习训练中，例如图像识别训练，每次从零开始训练都要消耗大量的时间和资源。而且当数据集比较少时，模型也难以拟合的情况。基于这种情况下，就出现了迁移学习，通过使用已经训练好的模型来初始化即将训练的网络，可以加快模型的收敛速度，而且还能提高模型的准确率。这个用于初始化训练网络的模型是使用大型数据集训练得到的一个模型，而且模型已经完全收敛。最好训练的模型和预训练的模型是同一个网络，这样可以最大限度地初始化全部层。  \n",
    "\n",
    "\n",
    "本次实验，就来探讨一下迁移学习方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 阶段一：初步训练模型\n",
    "本章使用的预训练模型是PaddlePaddle官方提供的ResNet50网络模型，训练的数据集是手写字体识别。\n",
    "\n",
    "首先导入相关的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#查看paddle版本号\r\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义一个残差神经网络，这个网络是PaddlePaddle官方提供的，模型地址为[models_name](https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleCV/image_classification/models_name)。这个网络是在每一个层都由指定参数名字，这是为了方便初始化网络模型，如果网络的结构发生变化了，但是名字没有变化，之后使用预训练模型初始化时，就可以根据每个参数的名字初始化对应的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义残差神经网络（ResNet）\n",
    "def resnet50(input):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 6, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            conv_name = \"res\" + str(block + 2) + chr(97 + i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    return pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义图片数据和标签数据的输入层，本章使用的图片数据集是手写字体。这个通过使用PaddlePaddle的接口得到的数据集的图片是单通道宽高都是28的灰度图，总类别是10种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入层\n",
    "image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "获取一个基本的模型，并从主程序中克隆一个基本的程序，用于之后加载参数使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取分类器\n",
    "pool = resnet50(image)\n",
    "# 停止梯度下降\n",
    "pool.stop_gradient = True\n",
    "# 由这里创建一个基本的主程序\n",
    "base_model_program = fluid.default_main_program().clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这里再加上网络的分类器，因为预训练模型的类别数量是1000，所以要重新修改分类器。这个也是训练新模型的最大不同点，通过分离分类器来解决两个数据集的不同类别的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这里再重新加载网络的分类器，大小为本项目的分类大小\n",
    "model = fluid.layers.fc(input=pool, size=10, act='softmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "然后是获取损失函数，准确率函数和优化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)\n",
    "\n",
    "# 获取训练和测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "# 定义优化方法\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=1e-3)\n",
    "opts = optimizer.minimize(avg_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "获取flowers数据集，因为这里不需要使用测试，所以这里也不需要读取测试数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 在线获取数据\n",
    "\n",
    "train_reader = paddle.batch(paddle.reader.shuffle(paddle.dataset.mnist.train(),buf_size=512), batch_size=128)\n",
    "test_reader = paddle.batch(paddle.dataset.mnist.test(), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "创建执行器，最好是使用GPU进行训练，因为数据集和网络都是比较大的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个使用CPU的解析器\n",
    "#place = fluid.CUDAPlace(0)\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "# 进行参数初始化\n",
    "exe.run(fluid.default_startup_program())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这里就是加载预训练模型的重点，通过if_exist函数判断网络所需的模型文件是否存在，然后再通过调用`fluid.io.load_vars`加载存在的模型文件。要留意的是这里使用的是之前克隆的基本程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 官方提供的原预训练模型\n",
    "src_pretrain_model_path = 'ResNet50_pretrained/'\n",
    "\n",
    "\n",
    "# 通过这个函数判断模型文件是否存在\n",
    "def if_exist(var):\n",
    "    path = os.path.join(src_pretrain_model_path, var.name)\n",
    "    exist = os.path.exists(path)\n",
    "    if exist:\n",
    "        print('Load model: %s' % path)\n",
    "    return exist\n",
    "\n",
    "\n",
    "# 加载模型文件，只加载存在模型的模型文件\n",
    "fluid.io.load_vars(executor=exe, dirname=src_pretrain_model_path, predicate=if_exist, main_program=base_model_program)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "然后使用这个预训练模型进行训练10个Pass。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 优化内存\n",
    "optimized = fluid.transpiler.memory_optimize(input_program=fluid.default_main_program(), print_log=False)\n",
    "\n",
    "# 定义输入数据维度\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])\n",
    "\n",
    "# 训练10次\n",
    "for pass_id in range(10):\n",
    "    # 进行训练\n",
    "    for batch_id, data in enumerate(train_reader()):\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),\n",
    "                                        feed=feeder.feed(data),\n",
    "                                        fetch_list=[avg_cost, acc])\n",
    "        # 每100个batch打印一次信息\n",
    "        if batch_id % 10 == 0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练结束之后，使用`fluid.io.save_params`接口保存参数，这个是已经符合这个数据集类别数量的，所以之后会使用都这个模型直接初始化模型，不需要再分离分类器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存参数模型\n",
    "save_pretrain_model_path = 'ResNet50_pretrained/'\n",
    "# 删除旧的模型文件\n",
    "shutil.rmtree(save_pretrain_model_path, ignore_errors=True)\n",
    "# 创建保持模型文件目录\n",
    "os.makedirs(save_pretrain_model_path)\n",
    "# 保存参数模型\n",
    "fluid.io.save_params(executor=exe, dirname=save_pretrain_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "到这里预训练的第一步处理原预训练模型算是完成了，接下来就是使用这个已经处理过的模型正式训练了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 阶段二：使用过的模型开始正式训练\n",
    "这一部分是使用已经处理过的模型开始正式训练，重启kernel，再运行以下代码。首先导入相关的依赖包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义一个残差神经网络，这个残差神经网络跟上面的基本一样的，只是把分类器也加进去了，这是一个完整的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义残差神经网络（ResNet）\n",
    "def resnet50(input, class_dim):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 6, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            conv_name = \"res\" + str(block + 2) + chr(97 + i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    output = fluid.layers.fc(input=pool, size=class_dim, act='softmax')\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "然后定义一系列所需的函数，输入层，神经网络的分类器，损失函数，准确率函数，优化方法，获取flowers训练数据和测试数据，并创建一个执行器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入层\n",
    "image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "\n",
    "# 获取分类器\n",
    "model = resnet50(image, 10)\n",
    "\n",
    "# 获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)\n",
    "\n",
    "# 获取训练和测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "# 定义优化方法\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=1e-3)\n",
    "opts = optimizer.minimize(avg_cost)\n",
    "\n",
    "# 获取MNIST数据\n",
    "train_reader = paddle.batch(paddle.reader.shuffle(paddle.dataset.mnist.train(),buf_size=512), batch_size=128)\n",
    "test_reader = paddle.batch(paddle.dataset.mnist.test(), batch_size=128)\n",
    "\n",
    "# 定义一个使用CPU的解析器\n",
    "#place = fluid.CUDAPlace(0)\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "# 进行参数初始化\n",
    "exe.run(fluid.default_startup_program())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这里可以使用`fluid.io.load_params`接口加载已经处理过的预训练模型文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 把阶段一训练好的模型 导入进来，作为预训练模型\n",
    "pretrained_model_path = 'ResNet50_pretrained/'\n",
    "\n",
    "# 加载经过处理的模型\n",
    "fluid.io.load_params(executor=exe, dirname=pretrained_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "之后就可以正常训练了，从训练输出的日志可以看出，模型收敛得非常快，而且准确率还非常高，如果没有使用预训练模型是很难达到这种准确率的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入数据维度\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])\n",
    "\n",
    "# 训练10次\n",
    "for pass_id in range(10):\n",
    "    # 进行训练\n",
    "    for batch_id, data in enumerate(train_reader()):\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),\n",
    "                                        feed=feeder.feed(data),\n",
    "                                        fetch_list=[avg_cost, acc])\n",
    "        # 每100个batch打印一次信息\n",
    "        if batch_id % 10 == 0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "\n",
    "    # 进行测试\n",
    "    test_accs = []\n",
    "    test_costs = []\n",
    "    for batch_id, data in enumerate(test_reader()):\n",
    "        test_cost, test_acc = exe.run(program=test_program,\n",
    "                                      feed=feeder.feed(data),\n",
    "                                      fetch_list=[avg_cost, acc])\n",
    "        test_accs.append(test_acc[0])\n",
    "        test_costs.append(test_cost[0])\n",
    "    # 求测试结果的平均值\n",
    "    test_cost = (sum(test_costs) / len(test_costs))\n",
    "    test_acc = (sum(test_accs) / len(test_accs))\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练结束之后，可以保存预测模型用于之后的预测使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存预测模型\n",
    "save_path = 'models/infer_model/'\n",
    "# 删除旧的模型文件\n",
    "shutil.rmtree(save_path, ignore_errors=True)\n",
    "# 创建保持模型文件目录\n",
    "os.makedirs(save_path)\n",
    "# 保存预测模型\n",
    "fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[model], executor=exe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
